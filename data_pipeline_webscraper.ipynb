{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T00:40:17.595309Z",
     "start_time": "2019-12-03T00:40:16.208594Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import requests\n",
    "import csv \n",
    "from lxml.html import fromstring\n",
    "import lxml.html as lh\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "import json\n",
    "import ast\n",
    "import os\n",
    "from urllib.request import Request, urlopen \n",
    "import shopify \n",
    "from optparse import OptionParser\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "# Input from user\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "# Input from user\n",
    "url = \"https://southernwesternboutique.myshopify.com/collections/bottoms-1?sort_by=price-ascending#MainContent\"\n",
    "# Making the website believe that you are accessing it using a mozilla browser\n",
    "req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "webpage = urlopen(req).read()\n",
    "# Creating a BeautifulSoup object of the html page for easy extraction of data.\n",
    "soup = BeautifulSoup(webpage, 'html.parser')\n",
    "def retrieve_bottom_prices():\n",
    "    bottoms = soup.find_all('span', class_=\"price-item price-item--regular\"\"\")\n",
    "    bottoms = {'PRICE:':[item.text for item in bottoms]}\n",
    "    list_of_rows = []\n",
    "    for row in soup.findAll('dl'):\n",
    "        list_of_cells = []\n",
    "        for cell in row.findAll([\"dd\"]):\n",
    "            text = cell.text\n",
    "            text = text.strip('\\t\\r\\n\\dd\\dt\\dl') \n",
    "            text = text.strip('\\n')\n",
    "            text = text.strip('\\n      \\n') \n",
    "            text = text.strip('\\n      \\n')\n",
    "            text = text.strip('Sale')\n",
    "            list_of_cells.append(text)\n",
    "        list_of_rows.append(list_of_cells)        \n",
    "    bottoms = pd.DataFrame(list_of_rows,columns=['PRICES','PRICE:'])\n",
    "    bottoms=bottoms.to_csv(\"gross_data/prices.csv\", header = True, index = True)  \n",
    "    bottoms = pd.read_csv('gross_data/prices.csv')\n",
    "    bottoms = bottoms.drop(['PRICES'],axis=1)\n",
    "    return bottoms\n",
    "def retrieve_bottom_products():\n",
    "    description = soup.find_all('div', class_=\"h4 grid-view-item__title product-card__title\" ) \n",
    "    description = {'DESCRIPTION:':[item.text for item in description]}\n",
    "    description = pd.DataFrame(description)\n",
    "#     header = 'DESCRIPTION:'\n",
    "    description.to_csv('gross_data/products.csv', header = True, index = True)\n",
    "    return description\n",
    "\n",
    "prices = retrieve_bottom_prices()\n",
    "products = retrieve_bottom_products() \n",
    "data = prices.join(products) \n",
    "data['DESCRIPTION:'] = data['DESCRIPTION:'].str.replace('+', '')\n",
    "data['PRICE:'] = data['PRICE:'].str.replace('$', '') \n",
    "data['PRICE:'] = data['PRICE:'].str.replace('\\n', '') \n",
    "data = data.fillna(0.0)\n",
    "Sales_bottoms = data['PRICE:']\n",
    "# Sales_bottoms.to_csv('price_data/BOTTOMS_PRICE.csv',header=True, index=True)\n",
    "# Sales_bottoms = pd.DataFrame(Sales_bottoms)\n",
    "Sales_desc = data['DESCRIPTION:']\n",
    "Sales_desc = pd.DataFrame(Sales_desc)\n",
    "Sales_desc = pd.get_dummies(Sales_desc)\n",
    "Sales_desc = Sales_desc.fillna(0.0)\n",
    "sale = Sales_desc.join(Sales_bottoms)\n",
    "sale.to_csv('price_data/combined_data/bottoms_combined.csv',index=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T00:40:19.571986Z",
     "start_time": "2019-12-03T00:40:17.597290Z"
    }
   },
   "outputs": [],
   "source": [
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "# Input from user\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "# Input from user\n",
    "url = \"https://southernwesternboutique.myshopify.com/collections/frontpage?sort_by=price-ascending#MainContent\"\n",
    "# Making the website believe that you are accessing it using a mozilla browser\n",
    "req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "webpage = urlopen(req).read()\n",
    "soup = BeautifulSoup(webpage, 'html.parser')\n",
    "def retrieve_tops_prices():\n",
    "    price = soup.find_all('span', class_=\"price-item price-item--regular\"\"\")\n",
    "    price = {'PRICE:':[item.text for item in price]}\n",
    "    list_of_rows = []\n",
    "    for row in soup.findAll('dl'):\n",
    "        list_of_cells = []\n",
    "        for cell in row.findAll([\"dd\"]):\n",
    "            text = cell.text\n",
    "            text = text.strip('\\t\\r\\n\\dd\\dt\\dl') \n",
    "            text = text.strip('\\n')\n",
    "            text = text.strip('\\n      \\n')\n",
    "            text = text.strip('\\n      \\n')\n",
    "            text = text.strip('Sale')\n",
    "            list_of_cells.append(text)\n",
    "        list_of_rows.append(list_of_cells)        \n",
    "    price = pd.DataFrame(list_of_rows,columns=['PRICES','PRICE:'])\n",
    "    price=price.to_csv(\"gross_data/tops_price.csv\", header = True, index = True)  \n",
    "    price = pd.read_csv('gross_data/tops_price.csv')\n",
    "    price= price.drop(['PRICES'],axis=1)\n",
    "    return price\n",
    "def retrieve_top_products():\n",
    "    description = soup.find_all('div', class_=\"h4 grid-view-item__title product-card__title\" ) \n",
    "    description = {'DESCRIPTION:':[item.text for item in description]}\n",
    "    description = pd.DataFrame(description)\n",
    "#     header = 'DESCRIPTION:'\n",
    "    description.to_csv('gross_data/tops_products.csv', header = True, index = True)\n",
    "    return description\n",
    "prices = retrieve_tops_prices()\n",
    "products = retrieve_top_products() \n",
    "new_data = prices.join(products)\n",
    "new_data = new_data.fillna(0.0)\n",
    "new_data['DESCRIPTION:'] = new_data['DESCRIPTION:'].str.replace('+', '')\n",
    "new_data['PRICE:'] = new_data['PRICE:'].str.replace('$', '') \n",
    "new_data['PRICE:'] = new_data['PRICE:'].str.replace('\\n', '') \n",
    "\n",
    "tops_price = new_data['PRICE:'] \n",
    "# tops_price.to_csv('price_data/TOPS_PRICE.csv',header=True, index=True)\n",
    "# tops_price= pd.DataFrame(tops_price)\n",
    "tops_desc = new_data['DESCRIPTION:']\n",
    "tops_desc= pd.DataFrame(tops_desc)\n",
    "tops_desc = pd.get_dummies(tops_desc)\n",
    "tops_desc = tops_desc.fillna(0.0)\n",
    "top = tops_desc.join(tops_price) \n",
    "top.to_csv('price_data/combined_data/tops_combined.csv',index=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T00:40:20.555009Z",
     "start_time": "2019-12-03T00:40:19.573869Z"
    }
   },
   "outputs": [],
   "source": [
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "# Input from user\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "# Input from user\n",
    "url = \"https://southernwesternboutique.myshopify.com/collections/shop?sort_by=price-ascending#MainContent\"\n",
    "# Making the website believe that you are accessing it using a mozilla browser\n",
    "req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "webpage = urlopen(req).read()\n",
    "soup = BeautifulSoup(webpage, 'html.parser')\n",
    "def retrieve_plus_prices():\n",
    "    price = soup.find_all('span', class_=\"price-item price-item--regular\"\"\")\n",
    "    price = {'PRICE:':[item.text for item in price]}\n",
    "    list_of_rows = []\n",
    "    for row in soup.findAll('dl'):\n",
    "        list_of_cells = []\n",
    "        for cell in row.findAll([\"dd\"]):\n",
    "            text = cell.text\n",
    "            text = text.strip('\\t\\r\\n\\dd\\dt\\dl') \n",
    "            text = text.strip('\\n')\n",
    "            text = text.strip('\\n      \\n')\n",
    "            text = text.strip('\\n      \\n')\n",
    "            text = text.strip('Sale')\n",
    "            list_of_cells.append(text)\n",
    "        list_of_rows.append(list_of_cells)        \n",
    "    price = pd.DataFrame(list_of_rows,columns=['PRICES','PRICE:'])\n",
    "    price=price.to_csv(\"gross_data/plus_price.csv\", header = True, index = True)  \n",
    "    price = pd.read_csv('gross_data/plus_price.csv')\n",
    "    price= price.drop(['PRICES'],axis=1)\n",
    "    return price\n",
    "def retrieve_plus_products():\n",
    "    description = soup.find_all('div', class_=\"h4 grid-view-item__title product-card__title\" ) \n",
    "    description = {'DESCRIPTION:':[item.text for item in description]}\n",
    "    description = pd.DataFrame(description)\n",
    "#     header = 'DESCRIPTION:'\n",
    "    description.to_csv('gross_data/plus_products.csv', header = True, index = True)\n",
    "    return description\n",
    "prices = retrieve_plus_prices()\n",
    "products = retrieve_plus_products() \n",
    "new_data = prices.join(products)\n",
    "new_data = new_data.fillna(0.0)\n",
    "new_data['DESCRIPTION:'] = new_data['DESCRIPTION:'].str.replace('+', '')\n",
    "new_data['PRICE:'] = new_data['PRICE:'].str.replace('$', '') \n",
    "new_data['PRICE:'] = new_data['PRICE:'].str.replace('\\n', '') \n",
    "\n",
    "plus_price = new_data['PRICE:'] \n",
    "# plus_price.to_csv('price_data/PLUS_PRICE.csv',header=True, index=True)\n",
    "# plus_price= pd.DataFrame(plus_price)\n",
    "plus_desc = new_data['DESCRIPTION:']\n",
    "plus_desc= pd.DataFrame(plus_desc)\n",
    "plus_desc = pd.get_dummies(plus_desc)\n",
    "plus_desc = plus_desc.fillna(0.0)\n",
    "pl = plus_desc.join(plus_price)\n",
    "pl.to_csv('price_data/combined_data/plus_combined.csv',index=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T00:40:21.504051Z",
     "start_time": "2019-12-03T00:40:20.561968Z"
    }
   },
   "outputs": [],
   "source": [
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "# Input from user\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "# Input from user\n",
    "url = \"https://southernwesternboutique.myshopify.com/collections/dresses?sort_by=price-ascending#MainContent\"\n",
    "# Making the website believe that you are accessing it using a mozilla browser\n",
    "req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "webpage = urlopen(req).read()\n",
    "soup = BeautifulSoup(webpage, 'html.parser')\n",
    "def retrieve_dresses_prices():\n",
    "    price = soup.find_all('span', class_=\"price-item price-item--regular\"\"\")\n",
    "    price = {'PRICE:':[item.text for item in price]}\n",
    "    list_of_rows = []\n",
    "    for row in soup.findAll('dl'):\n",
    "        list_of_cells = []\n",
    "        for cell in row.findAll([\"dd\"]):\n",
    "            text = cell.text\n",
    "            text = text.strip('\\t\\r\\n\\dd\\dt\\dl') \n",
    "            text = text.strip('\\n')\n",
    "            text = text.strip('\\n      \\n')\n",
    "            text = text.strip('\\n      \\n')\n",
    "            text = text.strip('Sale')\n",
    "            list_of_cells.append(text)\n",
    "        list_of_rows.append(list_of_cells)        \n",
    "    price = pd.DataFrame(list_of_rows,columns=['PRICES','PRICE:'])\n",
    "    price=price.to_csv(\"gross_data/dresses_price.csv\", header = True, index = True)  \n",
    "    price = pd.read_csv('gross_data/dresses_price.csv')\n",
    "    price= price.drop(['PRICES'],axis=1)\n",
    "    return price\n",
    "def retrieve_dresses_products():\n",
    "    description = soup.find_all('div', class_=\"h4 grid-view-item__title product-card__title\" ) \n",
    "    description = {'DESCRIPTION:':[item.text for item in description]}\n",
    "    description = pd.DataFrame(description)\n",
    "#     header = 'DESCRIPTION:'\n",
    "    description.to_csv('gross_data/dresses_products.csv', header = True, index = True)\n",
    "    return description\n",
    "prices = retrieve_dresses_prices()\n",
    "products = retrieve_dresses_products() \n",
    "new_data = prices.join(products)\n",
    "new_data = new_data.fillna(0.0)\n",
    "new_data['DESCRIPTION:'] = new_data['DESCRIPTION:'].str.replace('+', '')\n",
    "new_data['PRICE:'] = new_data['PRICE:'].str.replace('$', '') \n",
    "new_data['PRICE:'] = new_data['PRICE:'].str.replace('\\n', '') \n",
    "\n",
    "dresses_price = new_data['PRICE:'] \n",
    "# dresses_price.to_csv('price_data/DRESSES_PRICE.CSV',header=True, index=True)\n",
    "# dresses_price= pd.DataFrame(dresses_price) \n",
    "dresses_desc = new_data['DESCRIPTION:']\n",
    "dresses_desc= pd.DataFrame(dresses_desc)\n",
    "dresses_desc = pd.get_dummies(dresses_desc)\n",
    "dresses_desc = dresses_desc.fillna(0.0)\n",
    "dress = dresses_desc.join(dresses_price)\n",
    "dress.to_csv('price_data/combined_data/dresses_joined.csv',header=True,index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T00:40:22.526443Z",
     "start_time": "2019-12-03T00:40:21.504765Z"
    }
   },
   "outputs": [],
   "source": [
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "# Input from user\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "# Input from user\n",
    "url = \"https://southernwesternboutique.myshopify.com/collections/outerwear-cardigans?sort_by=price-ascending#MainContent\"\n",
    "# Making the website believe that you are accessing it using a mozilla browser\n",
    "req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "webpage = urlopen(req).read()\n",
    "soup = BeautifulSoup(webpage, 'html.parser')\n",
    "def retrieve_cardigans_prices():\n",
    "    price = soup.find_all('span', class_=\"price-item price-item--regular\"\"\")\n",
    "    price = {'PRICE:':[item.text for item in price]}\n",
    "    list_of_rows = []\n",
    "    for row in soup.findAll('dl'):\n",
    "        list_of_cells = []\n",
    "        for cell in row.findAll([\"dd\"]):\n",
    "            text = cell.text\n",
    "            text = text.strip('\\t\\r\\n\\dd\\dt\\dl') \n",
    "            text = text.strip('\\n')\n",
    "            text = text.strip('\\n      \\n')\n",
    "            text = text.strip('\\n      \\n')\n",
    "            text = text.strip('Sale')\n",
    "            list_of_cells.append(text)\n",
    "        list_of_rows.append(list_of_cells)        \n",
    "    price = pd.DataFrame(list_of_rows,columns=['PRICES','PRICE:'])\n",
    "    price=price.to_csv(\"gross_data/cardigans_price.csv\", header = True, index = True)  \n",
    "    price = pd.read_csv('gross_data/cardigans_price.csv')\n",
    "    price= price.drop(['PRICES'],axis=1)\n",
    "    return price\n",
    "def retrieve_cardigans_products():\n",
    "    description = soup.find_all('div', class_=\"h4 grid-view-item__title product-card__title\" ) \n",
    "    description = {'DESCRIPTION:':[item.text for item in description]}\n",
    "    description = pd.DataFrame(description)\n",
    "#     header = 'DESCRIPTION:'\n",
    "    description.to_csv('gross_data/cardigans_products.csv', header = True, index = True)\n",
    "    return description\n",
    "prices = retrieve_cardigans_prices()\n",
    "products = retrieve_cardigans_products() \n",
    "new_data = prices.join(products)\n",
    "new_data = new_data.fillna(0.0)\n",
    "new_data['DESCRIPTION:'] = new_data['DESCRIPTION:'].str.replace('+', '')\n",
    "new_data['PRICE:'] = new_data['PRICE:'].str.replace('$', '') \n",
    "new_data['PRICE:'] = new_data['PRICE:'].str.replace('\\n', '') \n",
    "\n",
    "cardigans_price = new_data['PRICE:'] \n",
    "# cardigans_price.to_csv('price_data/CARDIGANS_PRICE.csv',header=True, index=True)\n",
    "# cardigans_price= pd.DataFrame(cardigans_price)\n",
    "cardigans_desc = new_data['DESCRIPTION:']\n",
    "cardigans_desc= pd.DataFrame(cardigans_desc)\n",
    "cardigans_desc = pd.get_dummies(cardigans_desc)\n",
    "cardigans_desc = cardigans_desc.fillna(0.0)\n",
    "cardi = cardigans_desc.join(cardigans_price)\n",
    "cardi.to_csv('price_data/combined_data/cardigans_combined.csv',index=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T00:40:23.110565Z",
     "start_time": "2019-12-03T00:40:22.528327Z"
    }
   },
   "outputs": [],
   "source": [
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "# Input from user\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "# Input from user\n",
    "url = \"https://southernwesternboutique.myshopify.com/collections/holiday-dress-collection-1?sort_by=price-ascending#MainContent\"\n",
    "# Making the website believe that you are accessing it using a mozilla browser\n",
    "req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "webpage = urlopen(req).read()\n",
    "soup = BeautifulSoup(webpage, 'html.parser')\n",
    "def retrieve_holiday_prices():\n",
    "    price = soup.find_all('span', class_=\"price-item price-item--regular\"\"\")\n",
    "    price = {'PRICE:':[item.text for item in price]}\n",
    "    list_of_rows = []\n",
    "    for row in soup.findAll('dl'):\n",
    "        list_of_cells = []\n",
    "        for cell in row.findAll([\"dd\"]):\n",
    "            text = cell.text\n",
    "            text = text.strip('\\t\\r\\n\\dd\\dt\\dl') \n",
    "            text = text.strip('\\n')\n",
    "            text = text.strip('\\n      \\n')\n",
    "            text = text.strip('\\n      \\n')\n",
    "            text = text.strip('Sale')\n",
    "            list_of_cells.append(text)\n",
    "        list_of_rows.append(list_of_cells)        \n",
    "    price = pd.DataFrame(list_of_rows,columns=['PRICES','PRICE:'])\n",
    "    price=price.to_csv(\"gross_data/holiday_price.csv\", header = True, index = True)  \n",
    "    price = pd.read_csv('gross_data/holiday_price.csv')\n",
    "    price= price.drop(['PRICES'],axis=1)\n",
    "    return price\n",
    "def retrieve_holiday_products():\n",
    "    description = soup.find_all('div', class_=\"h4 grid-view-item__title product-card__title\" ) \n",
    "    description = {'DESCRIPTION:':[item.text for item in description]}\n",
    "    description = pd.DataFrame(description)\n",
    "#     header = 'DESCRIPTION:'\n",
    "    description.to_csv('gross_data/holiday_products.csv', header = True, index = True)\n",
    "    return description\n",
    "prices = retrieve_holiday_prices()\n",
    "products = retrieve_holiday_products() \n",
    "new_data = prices.join(products)\n",
    "new_data = new_data.fillna(0.0)\n",
    "new_data['DESCRIPTION:'] = new_data['DESCRIPTION:'].str.replace('+', '')\n",
    "new_data['PRICE:'] = new_data['PRICE:'].str.replace('$', '') \n",
    "new_data['PRICE:'] = new_data['PRICE:'].str.replace('\\n', '') \n",
    "\n",
    "holiday_price = new_data['PRICE:'] \n",
    "# holiday_price.to_csv('price_data/HOLIDAY_PRICE.csv',header=True, index=True)\n",
    "# holiday_price= pd.DataFrame(holiday_price)\n",
    "holiday_desc = new_data['DESCRIPTION:']\n",
    "holiday_desc= pd.DataFrame(holiday_desc)\n",
    "holiday_desc = pd.get_dummies(holiday_desc)\n",
    "holiday_desc = holiday_desc.fillna(0.0)\n",
    "holiday = holiday_desc.join(holiday_price) \n",
    "holiday.to_csv('price_data/combined_data/combined_holiday_dresses.csv',index=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T00:40:23.879486Z",
     "start_time": "2019-12-03T00:40:23.112370Z"
    }
   },
   "outputs": [],
   "source": [
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "# Input from user\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "# Input from user\n",
    "url = \"https://southernwesternboutique.myshopify.com/collections/c-c-beanies-and-scarves?sort_by=price-ascending#MainContent\"\n",
    "# Making the website believe that you are accessing it using a mozilla browser\n",
    "req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "webpage = urlopen(req).read()\n",
    "soup = BeautifulSoup(webpage, 'html.parser')\n",
    "def retrieve_holiday2_prices():\n",
    "    price = soup.find_all('span', class_=\"price-item price-item--regular\"\"\")\n",
    "    price = {'PRICE:':[item.text for item in price]}\n",
    "    list_of_rows = []\n",
    "    for row in soup.findAll('dl'):\n",
    "        list_of_cells = []\n",
    "        for cell in row.findAll([\"dd\"]):\n",
    "            text = cell.text\n",
    "            text = text.strip('\\t\\r\\n\\dd\\dt\\dl') \n",
    "            text = text.strip('\\n')\n",
    "            text = text.strip('\\n      \\n')\n",
    "            text = text.strip('\\n      \\n')\n",
    "            text = text.strip('Sale')\n",
    "            list_of_cells.append(text)\n",
    "        list_of_rows.append(list_of_cells)        \n",
    "    price = pd.DataFrame(list_of_rows,columns=['PRICES','PRICE:'])\n",
    "    price=price.to_csv(\"gross_data/holiday2_price.csv\", header = True, index = True)  \n",
    "    price = pd.read_csv('gross_data/holiday2_price.csv')\n",
    "    price= price.drop(['PRICES'],axis=1)\n",
    "    return price\n",
    "def retrieve_holiday2_products():\n",
    "    description = soup.find_all('div', class_=\"h4 grid-view-item__title product-card__title\" ) \n",
    "    description = {'DESCRIPTION:':[item.text for item in description]}\n",
    "    description = pd.DataFrame(description)\n",
    "#     header = 'DESCRIPTION:'\n",
    "    description.to_csv('gross_data/holiday2_products.csv', header = True, index = True)\n",
    "    return description\n",
    "prices = retrieve_holiday2_prices()\n",
    "products = retrieve_holiday2_products() \n",
    "new_data = prices.join(products)\n",
    "new_data = new_data.fillna(0.0)\n",
    "new_data['DESCRIPTION:'] = new_data['DESCRIPTION:'].str.replace('+', '')\n",
    "new_data['PRICE:'] = new_data['PRICE:'].str.replace('$', '') \n",
    "new_data['PRICE:'] = new_data['PRICE:'].str.replace('\\n', '') \n",
    "\n",
    "holiday2_price = new_data['PRICE:'] \n",
    "# holiday2_price.to_csv('price_data/HOLIDAY_BEANIE_.csv',header=True, index=True)\n",
    "# holiday2_price= pd.DataFrame(holiday2_price)\n",
    "holiday2_desc = new_data['DESCRIPTION:']\n",
    "holiday2_desc= pd.DataFrame(holiday2_desc)\n",
    "holiday2_desc = pd.get_dummies(holiday2_desc)\n",
    "holiday2_desc = holiday2_desc.fillna(0.0)\n",
    "holiday2 = holiday2_desc.join(holiday2_price)\n",
    "holiday2.to_csv('price_data/combined_data/holiday_beanie_.csv',index=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T00:40:24.820449Z",
     "start_time": "2019-12-03T00:40:23.880414Z"
    }
   },
   "outputs": [],
   "source": [
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "# Input from user\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "# Input from user\n",
    "url = \"https://southernwesternboutique.myshopify.com/collections/graphic-tshirts-1/Graphic-T's?sort_by=price-ascending#MainContent\"\n",
    "# Making the website believe that you are accessing it using a mozilla browser\n",
    "req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "webpage = urlopen(req).read()\n",
    "soup = BeautifulSoup(webpage, 'html.parser')\n",
    "def retrieve_graphict_prices():\n",
    "    price = soup.find_all('span', class_=\"price-item price-item--regular\"\"\")\n",
    "    price = {'PRICE:':[item.text for item in price]}\n",
    "    list_of_rows = []\n",
    "    for row in soup.findAll('dl'):\n",
    "        list_of_cells = []\n",
    "        for cell in row.findAll([\"dd\"]):\n",
    "            text = cell.text\n",
    "            text = text.strip('\\t\\r\\n\\dd\\dt\\dl') \n",
    "            text = text.strip('\\n')\n",
    "            text = text.strip('\\n      \\n')\n",
    "            text = text.strip('\\n      \\n')\n",
    "            text = text.strip('Sale')\n",
    "            list_of_cells.append(text)\n",
    "        list_of_rows.append(list_of_cells)        \n",
    "    price = pd.DataFrame(list_of_rows,columns=['PRICES','PRICE:'])\n",
    "    price=price.to_csv(\"gross_data/graphict_price.csv\", header = True, index = True)  \n",
    "    price = pd.read_csv('gross_data/graphict_price.csv')\n",
    "    price= price.drop(['PRICES'],axis=1)\n",
    "    return price\n",
    "def retrieve_graphict_products():\n",
    "    description = soup.find_all('div', class_=\"h4 grid-view-item__title product-card__title\" ) \n",
    "    description = {'DESCRIPTION:':[item.text for item in description]}\n",
    "    description = pd.DataFrame(description)\n",
    "#     header = 'DESCRIPTION:'\n",
    "    description.to_csv('gross_data/graphict_products.csv', header = True, index = True)\n",
    "    return description\n",
    "prices = retrieve_graphict_prices()\n",
    "products = retrieve_graphict_products() \n",
    "new_data = prices.join(products)\n",
    "new_data = new_data.fillna(0.0)\n",
    "new_data['DESCRIPTION:'] = new_data['DESCRIPTION:'].str.replace('+', '')\n",
    "new_data['PRICE:'] = new_data['PRICE:'].str.replace('$', '') \n",
    "new_data['PRICE:'] = new_data['PRICE:'].str.replace('\\n', '') \n",
    "\n",
    "graphict_price = new_data['PRICE:'] \n",
    "# graphict_price.to_csv('price_data/GRAPHICtee_PRICE.csv',header=True, index=True)\n",
    "# graphict_price= pd.DataFrame(graphict_price)\n",
    "graphict_desc = new_data['DESCRIPTION:']\n",
    "graphict_desc= pd.DataFrame(graphict_desc)\n",
    "graphict_desc = pd.get_dummies(graphict_desc)\n",
    "graphict_desc = graphict_desc.fillna(0.0)\n",
    "graphic = graphict_desc.join(graphict_price)\n",
    "graphic.to_csv('price_data/combined_data/graphic_tee.csv',index=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T00:40:25.736400Z",
     "start_time": "2019-12-03T00:40:24.821417Z"
    }
   },
   "outputs": [],
   "source": [
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "# Input from user\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "# Input from user\n",
    "url = \"https://southernwesternboutique.myshopify.com/collections/shoes-and-accessories?sort_by=price-ascending#MainContent\"\n",
    "# Making the website believe that you are accessing it using a mozilla browser\n",
    "req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "webpage = urlopen(req).read()\n",
    "soup = BeautifulSoup(webpage, 'html.parser')\n",
    "def retrieve_shoes_accesories_prices():\n",
    "    price = soup.find_all('span', class_=\"price-item price-item--regular\"\"\")\n",
    "    price = {'PRICE:':[item.text for item in price]}\n",
    "    list_of_rows = []\n",
    "    for row in soup.findAll('dl'):\n",
    "        list_of_cells = []\n",
    "        for cell in row.findAll([\"dd\"]):\n",
    "            text = cell.text\n",
    "            text = text.strip('\\t\\r\\n\\dd\\dt\\dl') \n",
    "            text = text.strip('\\n')\n",
    "            text = text.strip('\\n      \\n')\n",
    "            text = text.strip('\\n      \\n')\n",
    "            text = text.strip('Sale')\n",
    "            list_of_cells.append(text)\n",
    "        list_of_rows.append(list_of_cells)        \n",
    "    price = pd.DataFrame(list_of_rows,columns=['PRICES','PRICE:'])\n",
    "    price=price.to_csv(\"gross_data/shoes_accesories_price.csv\", header = True, index = True)  \n",
    "    price = pd.read_csv('gross_data/shoes_accesories_price.csv')\n",
    "    price= price.drop(['PRICES'],axis=1)\n",
    "    return price\n",
    "def retrieve_shoes_accesories_products():\n",
    "    description = soup.find_all('div', class_=\"h4 grid-view-item__title product-card__title\" ) \n",
    "    description = {'DESCRIPTION:':[item.text for item in description]}\n",
    "    description = pd.DataFrame(description)\n",
    "#     header = 'DESCRIPTION:'\n",
    "    description.to_csv('gross_data/shoes_accesories_products.csv', header = True, index = True)\n",
    "    return description\n",
    "prices = retrieve_shoes_accesories_prices()\n",
    "products = retrieve_shoes_accesories_products() \n",
    "new_data = prices.join(products)\n",
    "new_data = new_data.fillna(0.0)\n",
    "new_data['DESCRIPTION:'] = new_data['DESCRIPTION:'].str.replace('+', '')\n",
    "new_data['PRICE:'] = new_data['PRICE:'].str.replace('$', '') \n",
    "new_data['PRICE:'] = new_data['PRICE:'].str.replace('\\n', '') \n",
    "\n",
    "shoes_accesories_price = new_data['PRICE:'] \n",
    "# shoes_accesories_price.to_csv('price_data/SHOES_ACCESSORIES_PRICE.csv',header=True, index=True)\n",
    "# shoes_accesories_price= pd.DataFrame(shoes_accesories_price)\n",
    "shoes_accesories_desc = new_data['DESCRIPTION:']\n",
    "shoes_accesories_desc= pd.DataFrame(shoes_accesories_desc)\n",
    "shoes_accesories_desc = pd.get_dummies(shoes_accesories_desc)\n",
    "shoes_accesories_desc = shoes_accesories_desc.fillna(0.0)\n",
    "shoes = shoes_accesories_desc.join(shoes_accesories_price)\n",
    "shoes.to_csv('price_data/combined_data/shoes_accesories_joined.csv',header=True,index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T00:40:26.607403Z",
     "start_time": "2019-12-03T00:40:25.738305Z"
    }
   },
   "outputs": [],
   "source": [
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "# Input from user\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "# Input from user\n",
    "url = \"https://southernwesternboutique.myshopify.com/collections/senegnce-lipsense-shadowsense-1\"\n",
    "# Making the website believe that you are accessing it using a mozilla browser\n",
    "req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "webpage = urlopen(req).read()\n",
    "soup = BeautifulSoup(webpage, 'html.parser')\n",
    "def retrieve_lipsence_prices():\n",
    "    price = soup.find_all('span', class_=\"price-item price-item--regular\"\"\")\n",
    "    price = {'PRICE:':[item.text for item in price]}\n",
    "    list_of_rows = []\n",
    "    for row in soup.findAll('dl'):\n",
    "        list_of_cells = []\n",
    "        for cell in row.findAll([\"dd\"]):\n",
    "            text = cell.text\n",
    "            text = text.strip('\\t\\r\\n\\dd\\dt\\dl') \n",
    "            text = text.strip('\\n')\n",
    "            text = text.strip('\\n      \\n')\n",
    "            text = text.strip('\\n      \\n')\n",
    "            text = text.strip('Sale')\n",
    "            list_of_cells.append(text)\n",
    "        list_of_rows.append(list_of_cells)        \n",
    "    price = pd.DataFrame(list_of_rows,columns=['PRICES','PRICE:'])\n",
    "    price=price.to_csv(\"gross_data/lipsence_price.csv\", header = True, index = True)  \n",
    "    price = pd.read_csv('gross_data/lipsence_price.csv')\n",
    "    price= price.drop(['PRICES'],axis=1)\n",
    "    return price\n",
    "def retrieve_lipsence_products():\n",
    "    description = soup.find_all('div', class_=\"h4 grid-view-item__title product-card__title\" ) \n",
    "    description = {'DESCRIPTION:':[item.text for item in description]}\n",
    "    description = pd.DataFrame(description)\n",
    "#     header = 'DESCRIPTION:'\n",
    "    description.to_csv('gross_data/lipsence_products.csv', header = True, index = True)\n",
    "    return description\n",
    "prices = retrieve_lipsence_prices()\n",
    "products = retrieve_lipsence_products() \n",
    "new_data = prices.join(products)\n",
    "new_data = new_data.fillna(0.0)\n",
    "new_data['DESCRIPTION:'] = new_data['DESCRIPTION:'].str.replace('+', '')\n",
    "new_data['PRICE:'] = new_data['PRICE:'].str.replace('$', '') \n",
    "new_data['PRICE:'] = new_data['PRICE:'].str.replace('\\n', '') \n",
    "\n",
    "lipsence_price = new_data['PRICE:'] \n",
    "# lipsence_price.to_csv('price_data/lipsence_price.csv',header=True, index=True)\n",
    "# lipsence_price= pd.DataFrame(lipsence_price)\n",
    "lipsence_desc = new_data['DESCRIPTION:']\n",
    "lipsence_desc= pd.DataFrame(lipsence_desc)\n",
    "lipsence_desc = pd.get_dummies(lipsence_desc)\n",
    "lipsence_desc = lipsence_desc.fillna(0.0)\n",
    "lip =lipsence_desc.join(lipsence_price)\n",
    "lip.to_csv('price_data/combined_data/lipscence_joined.csv',header=True,index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
